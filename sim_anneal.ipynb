{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(selected_features, X_train, X_test, y_train, y_test):\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_classifier.fit(X_train.iloc[:, selected_features], y_train)\n",
    "    y_pred = rf_classifier.predict(X_test.iloc[:, selected_features])\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "def simulated_annealing(X_train, X_test, y_train, y_test, initial_solution, max_iterations, temperature, cooling_rate):\n",
    "    current_solution = initial_solution\n",
    "    current_accuracy = get_accuracy(current_solution, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    best_solution = current_solution\n",
    "    best_accuracy = current_accuracy\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        # Generate a neighboring solution\n",
    "        neighbor_solution = current_solution.copy()\n",
    "        index_to_change = np.random.randint(0, len(neighbor_solution))\n",
    "        neighbor_solution[index_to_change] = 1 - neighbor_solution[index_to_change]  # Flip the feature selection\n",
    "\n",
    "        # Calculate the neighbor's accuracy\n",
    "        neighbor_accuracy = get_accuracy(neighbor_solution, X_train, X_test, y_train, y_test)\n",
    "\n",
    "        # Decide whether to move to the neighbor solution\n",
    "        if neighbor_accuracy > current_accuracy or np.random.rand() < np.exp((neighbor_accuracy - current_accuracy) / temperature):\n",
    "            current_solution = neighbor_solution\n",
    "            current_accuracy = neighbor_accuracy\n",
    "\n",
    "        # Update the best solution if needed\n",
    "        if current_accuracy > best_accuracy:\n",
    "            best_solution = current_solution\n",
    "            best_accuracy = current_accuracy\n",
    "\n",
    "        # Cool the temperature\n",
    "        temperature *= cooling_rate\n",
    "\n",
    "        if iteration % 10 == 0:\n",
    "            print(f\"Iteration {iteration}: Best Accuracy - {best_accuracy}\")\n",
    "\n",
    "    return best_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist.data, mnist.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# Assuming X_train, y_train, X_test, and y_test are already defined\n",
    "num_features = 28  # Change this according to your actual number of features\n",
    "pop_size = 16\n",
    "max_iter = 10\n",
    "\n",
    "num_particles = 16\n",
    "col_len = 28\n",
    "max_value = 783\n",
    "std_dev = 150\n",
    "mean = max_value / 2\n",
    "pop_size = (num_particles, col_len)\n",
    "\n",
    "population = np.random.normal(mean, std_dev, pop_size).astype(int)\n",
    "population[population > max_value] = max_value\n",
    "population[population < 0] = 0\n",
    "\n",
    "totalfeat = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert target labels to integers\n",
    "y = y.astype('int64')\n",
    "\n",
    "# Initialize a random solution (feature selection)\n",
    "initial_solution = np.random.randint(0, 2, size=len(X_train.columns))\n",
    "\n",
    "# Set parameters for simulated annealing\n",
    "max_iterations = 1000\n",
    "temperature = 1.0\n",
    "cooling_rate = 0.95\n",
    "\n",
    "# Run simulated annealing\n",
    "best_solution_sa = simulated_annealing(X_train, X_test, y_train, y_test, initial_solution, max_iterations, temperature, cooling_rate)\n",
    "\n",
    "# Print the best solution and its accuracy\n",
    "print(\"Best solution using Simulated Annealing:\", best_solution_sa)\n",
    "print(\"Best solution accuracy:\", get_accuracy(best_solution_sa, X_train, X_test, y_train, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
