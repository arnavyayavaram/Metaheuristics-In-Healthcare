{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist.data, mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# # fetch dataset \n",
    "# optical_recognition_of_handwritten_digits = fetch_ucirepo(id=80) \n",
    "  \n",
    "# # data (as pandas dataframes) \n",
    "# X = optical_recognition_of_handwritten_digits.data.features \n",
    "# y = optical_recognition_of_handwritten_digits.data.targets \n",
    "  \n",
    "# # metadata \n",
    "# print(optical_recognition_of_handwritten_digits.metadata) \n",
    "\n",
    "# # variable information \n",
    "# print(optical_recognition_of_handwritten_digits.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y= y.to_numpy()\n",
    "# y =y.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_classifier = SVC(kernel='linear', C=1.0)\n",
    "\n",
    "# svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_classifier = xgb.XGBClassifier()\n",
    "# xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_pop_fitness(pop, X_train, y_train, X_test, y_test):\n",
    "    fitness = []\n",
    "    for i in range(len(pop)):\n",
    "        columns = np.unique(pop[i])\n",
    "        \n",
    "        X_train_ind = X_train.iloc[:,columns]\n",
    "        rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        rf_classifier.fit(X_train_ind, y_train)\n",
    "\n",
    "        y_pred = rf_classifier.predict(X_test.iloc[:,columns])\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        fitness.append(accuracy)\n",
    "\n",
    "    return fitness\n",
    "\n",
    "def fit_svm(pop, X_train, y_train, X_test, y_test):\n",
    "    fitness = []\n",
    "    for i in range(len(pop)):\n",
    "        columns = np.unique(pop[i])\n",
    "        \n",
    "        X_train_ind = X_train.iloc[:, columns]\n",
    "        svm_classifier = SVC(kernel='linear', C=1.0)\n",
    "        svm_classifier.fit(X_train_ind, y_train)\n",
    "\n",
    "        y_pred = svm_classifier.predict(X_test.iloc[:, columns])\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        fitness.append(accuracy)\n",
    "\n",
    "    return fitness\n",
    "\n",
    "def fit_xgboost(pop, X_train, y_train, X_test, y_test):\n",
    "    fitness = []\n",
    "    for i in range(len(pop)):\n",
    "        columns = np.unique(pop[i])\n",
    "        \n",
    "        X_train_ind = X_train.iloc[:, columns]\n",
    "        xgb_classifier = xgb.XGBClassifier()\n",
    "        xgb_classifier.fit(X_train_ind, y_train)\n",
    "\n",
    "        y_pred = xgb_classifier.predict(X_test.iloc[:, columns])\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        fitness.append(accuracy)\n",
    "\n",
    "    return fitness\n",
    "\n",
    "def select_mating_pool(pop, fitness, num_parents):\n",
    "    # Selecting the best individuals in the current generation as parents for producing the offspring of the next generation.\n",
    "    parents = np.empty((num_parents, pop.shape[1]))\n",
    "    for parent_num in range(num_parents):\n",
    "        max_fitness_idx = np.where(fitness == np.max(fitness))\n",
    "        max_fitness_idx = max_fitness_idx[0][0]\n",
    "        parents[parent_num, :] = pop[max_fitness_idx, :]\n",
    "        fitness[max_fitness_idx] = -1\n",
    "    return parents\n",
    "\n",
    "def crossover(parents, offspring_size):\n",
    "    offspring = np.empty(offspring_size)\n",
    "\n",
    "    for k in range(offspring_size[0]):\n",
    "        # Always perform one-point crossover.\n",
    "        crossover_point = np.random.randint(1, parents.shape[1])\n",
    "        parent1_idx = k % parents.shape[0]\n",
    "        parent2_idx = (k + 1) % parents.shape[0]\n",
    "        offspring[k, :crossover_point] = parents[parent1_idx, :crossover_point]\n",
    "        offspring[k, crossover_point:] = parents[parent2_idx, crossover_point:]\n",
    "\n",
    "    return offspring\n",
    "\n",
    "def mutation(offspring_crossover):\n",
    "    # Mutation changes a single gene in each offspring randomly.\n",
    "    for idx in range(offspring_crossover.shape[0]):\n",
    "        # The random value to be added to the gene.\n",
    "        random_value = np.random.choice([-1, 0, 1], 1)\n",
    "        offspring_crossover[idx, 4] = offspring_crossover[idx, 4] + random_value\n",
    "    return offspring_crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[415 268 472 ... 349 294 439]\n",
      " [469 531 461 ... 400 455 589]\n",
      " [454 423 373 ... 313 472 144]\n",
      " ...\n",
      " [652 353 417 ... 106 525 311]\n",
      " [479 237 478 ... 336 640 314]\n",
      " [400 320 409 ... 420  96 207]]\n"
     ]
    }
   ],
   "source": [
    "col_len = 112\n",
    "\n",
    "sol_per_pop = 100\n",
    "num_parents_mating = 50\n",
    "\n",
    "pop_size = (sol_per_pop,col_len)\n",
    "\n",
    "max_value = 783 \n",
    "std_dev = 150\n",
    "mean = max_value / 2\n",
    "\n",
    "new_population = np.random.normal(mean, std_dev, pop_size).astype(int)\n",
    "\n",
    "new_population[new_population > max_value] = max_value\n",
    "new_population[new_population < 0] = 0\n",
    "\n",
    "print(new_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train = X_train[:10000]\n",
    "X_test = X_test[:3000]\n",
    "y_train = y_train[:10000]\n",
    "y_test = y_test[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9083333333333333, 0.9143333333333333, 0.886, 0.909, 0.9033333333333333, 0.8963333333333333, 0.9036666666666666, 0.91, 0.9193333333333333, 0.9153333333333333, 0.9066666666666666, 0.921, 0.8973333333333333, 0.899, 0.9116666666666666, 0.907, 0.9126666666666666, 0.9233333333333333, 0.9136666666666666, 0.9136666666666666, 0.9056666666666666, 0.9086666666666666, 0.9133333333333333, 0.9086666666666666, 0.9006666666666666, 0.905, 0.9116666666666666, 0.8976666666666666, 0.919, 0.9103333333333333, 0.911, 0.919, 0.9176666666666666, 0.9086666666666666, 0.912, 0.9043333333333333, 0.9036666666666666, 0.8933333333333333, 0.9136666666666666, 0.9016666666666666, 0.9056666666666666, 0.9113333333333333, 0.9073333333333333, 0.8993333333333333, 0.919, 0.9106666666666666, 0.9053333333333333, 0.9103333333333333, 0.9146666666666666, 0.9013333333333333, 0.9086666666666666, 0.918, 0.9023333333333333, 0.889, 0.902, 0.8993333333333333, 0.8786666666666667, 0.9153333333333333, 0.9053333333333333, 0.913, 0.8886666666666667, 0.9046666666666666, 0.908, 0.9073333333333333, 0.912, 0.9056666666666666, 0.908, 0.9136666666666666, 0.9253333333333333, 0.9053333333333333, 0.9093333333333333, 0.9166666666666666, 0.9003333333333333, 0.9123333333333333, 0.9013333333333333, 0.903, 0.8916666666666667, 0.9073333333333333, 0.9173333333333333, 0.9063333333333333, 0.9053333333333333, 0.9113333333333333, 0.9116666666666666, 0.913, 0.9126666666666666, 0.917, 0.9123333333333333, 0.91, 0.9216666666666666, 0.8986666666666666, 0.904, 0.906, 0.9126666666666666, 0.8936666666666667, 0.9076666666666666, 0.902, 0.911, 0.9096666666666666, 0.905, 0.9046666666666666]\n",
      "Generation :  0\n",
      "\n",
      "[0.9253333333333333, 0.9233333333333333, 0.9216666666666666, 0.921, 0.9193333333333333, 0.919, 0.919, 0.919, 0.918, 0.9176666666666666, 0.9173333333333333, 0.917, 0.9166666666666666, 0.9153333333333333, 0.9153333333333333, 0.9146666666666666, 0.9143333333333333, 0.9136666666666666, 0.9136666666666666, 0.9136666666666666, 0.9136666666666666, 0.9133333333333333, 0.913, 0.913, 0.9126666666666666, 0.9126666666666666, 0.9126666666666666, 0.9123333333333333, 0.9123333333333333, 0.912, 0.912, 0.9116666666666666, 0.9116666666666666, 0.9116666666666666, 0.9113333333333333, 0.9113333333333333, 0.911, 0.911, 0.9106666666666666, 0.9103333333333333, 0.9103333333333333, 0.91, 0.91, 0.9096666666666666, 0.9093333333333333, 0.909, 0.9086666666666666, 0.9086666666666666, 0.9086666666666666, 0.9086666666666666, 0.9236666666666666, 0.9136666666666666, 0.9143333333333333, 0.9143333333333333, 0.9153333333333333, 0.9206666666666666, 0.9196666666666666, 0.912, 0.9106666666666666, 0.909, 0.9153333333333333, 0.9113333333333333, 0.9166666666666666, 0.92, 0.9173333333333333, 0.9086666666666666, 0.9153333333333333, 0.9136666666666666, 0.9196666666666666, 0.9133333333333333, 0.915, 0.9153333333333333, 0.911, 0.9146666666666666, 0.9176666666666666, 0.915, 0.918, 0.9093333333333333, 0.9016666666666666, 0.9016666666666666, 0.9076666666666666, 0.905, 0.908, 0.913, 0.907, 0.9096666666666666, 0.912, 0.9093333333333333, 0.9136666666666666, 0.898, 0.9083333333333333, 0.9103333333333333, 0.9113333333333333, 0.9103333333333333, 0.9176666666666666, 0.908, 0.914, 0.907, 0.9056666666666666, 0.9116666666666666]\n",
      "[0.9253333333333333, 0.9236666666666666, 0.9233333333333333, 0.9216666666666666, 0.921, 0.9206666666666666, 0.92, 0.9196666666666666, 0.9196666666666666, 0.9193333333333333, 0.919, 0.919, 0.919, 0.918, 0.918, 0.9176666666666666, 0.9176666666666666, 0.9176666666666666, 0.9173333333333333, 0.9173333333333333, 0.917, 0.9166666666666666, 0.9166666666666666, 0.9153333333333333, 0.9153333333333333, 0.9153333333333333, 0.9153333333333333, 0.9153333333333333, 0.9153333333333333, 0.915, 0.915, 0.9146666666666666, 0.9146666666666666, 0.9143333333333333, 0.9143333333333333, 0.9143333333333333, 0.914, 0.9136666666666666, 0.9136666666666666, 0.9136666666666666, 0.9136666666666666, 0.9136666666666666, 0.9136666666666666, 0.9136666666666666, 0.9133333333333333, 0.9133333333333333, 0.913, 0.913, 0.913, 0.9126666666666666, 0.9256666666666666, 0.9236666666666666, 0.9133333333333333, 0.917, 0.9123333333333333, 0.9226666666666666, 0.905, 0.917, 0.9256666666666666, 0.9186666666666666, 0.9156666666666666, 0.921, 0.919, 0.9136666666666666, 0.9106666666666666, 0.9176666666666666, 0.9196666666666666, 0.9113333333333333, 0.907, 0.917, 0.9056666666666666, 0.9136666666666666, 0.9166666666666666, 0.9143333333333333, 0.921, 0.9226666666666666, 0.907, 0.9163333333333333, 0.911, 0.915, 0.9183333333333333, 0.915, 0.9153333333333333, 0.9133333333333333, 0.912, 0.9116666666666666, 0.91, 0.9193333333333333, 0.9146666666666666, 0.9116666666666666, 0.9143333333333333, 0.9106666666666666, 0.9173333333333333, 0.9066666666666666, 0.9136666666666666, 0.918, 0.9116666666666666, 0.9106666666666666, 0.8993333333333333, 0.9186666666666666]\n",
      "[0.9256666666666666, 0.9256666666666666, 0.9253333333333333, 0.9236666666666666, 0.9236666666666666, 0.9233333333333333, 0.9226666666666666, 0.9226666666666666, 0.9216666666666666, 0.921, 0.921, 0.921, 0.9206666666666666, 0.92, 0.9196666666666666, 0.9196666666666666, 0.9196666666666666, 0.9193333333333333, 0.9193333333333333, 0.919, 0.919, 0.919, 0.919, 0.9186666666666666, 0.9186666666666666, 0.9183333333333333, 0.918, 0.918, 0.918, 0.9176666666666666, 0.9176666666666666, 0.9176666666666666, 0.9176666666666666, 0.9173333333333333, 0.9173333333333333, 0.9173333333333333, 0.917, 0.917, 0.917, 0.917, 0.9166666666666666, 0.9166666666666666, 0.9166666666666666, 0.9163333333333333, 0.9156666666666666, 0.9153333333333333, 0.9153333333333333, 0.9153333333333333, 0.9153333333333333, 0.9153333333333333, 0.9186666666666666, 0.9173333333333333, 0.9243333333333333, 0.9236666666666666, 0.9246666666666666, 0.913, 0.923, 0.926, 0.919, 0.9253333333333333, 0.919, 0.9143333333333333, 0.9086666666666666, 0.9123333333333333, 0.926, 0.916, 0.917, 0.9183333333333333, 0.918, 0.914, 0.9193333333333333, 0.9216666666666666, 0.9103333333333333, 0.9183333333333333, 0.9093333333333333, 0.9063333333333333, 0.9226666666666666, 0.906, 0.8943333333333333, 0.9136666666666666, 0.9123333333333333, 0.9093333333333333, 0.9133333333333333, 0.9166666666666666, 0.9086666666666666, 0.909, 0.9153333333333333, 0.9173333333333333, 0.9186666666666666, 0.9186666666666666, 0.916, 0.918, 0.918, 0.9083333333333333, 0.92, 0.9186666666666666, 0.9123333333333333, 0.9183333333333333, 0.916, 0.9163333333333333]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\siddh\\OneDrive\\Documents\\Metaheuristics-In-Healthcare\\1.ipynb Cell 14\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/siddh/OneDrive/Documents/Metaheuristics-In-Healthcare/1.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m num_generations \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/siddh/OneDrive/Documents/Metaheuristics-In-Healthcare/1.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m generation \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_generations):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/siddh/OneDrive/Documents/Metaheuristics-In-Healthcare/1.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m# Measing the fitness of each chromosome in the population.\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/siddh/OneDrive/Documents/Metaheuristics-In-Healthcare/1.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     fitness \u001b[39m=\u001b[39m cal_pop_fitness(new_population, X_train,y_train,X_test,y_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/siddh/OneDrive/Documents/Metaheuristics-In-Healthcare/1.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(fitness)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/siddh/OneDrive/Documents/Metaheuristics-In-Healthcare/1.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# Selecting the best parents in the population for mating.\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\siddh\\OneDrive\\Documents\\Metaheuristics-In-Healthcare\\1.ipynb Cell 14\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/siddh/OneDrive/Documents/Metaheuristics-In-Healthcare/1.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m X_train_ind \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39miloc[:,columns]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/siddh/OneDrive/Documents/Metaheuristics-In-Healthcare/1.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m rf_classifier \u001b[39m=\u001b[39m RandomForestClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/siddh/OneDrive/Documents/Metaheuristics-In-Healthcare/1.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m rf_classifier\u001b[39m.\u001b[39;49mfit(X_train_ind, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/siddh/OneDrive/Documents/Metaheuristics-In-Healthcare/1.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m y_pred \u001b[39m=\u001b[39m rf_classifier\u001b[39m.\u001b[39mpredict(X_test\u001b[39m.\u001b[39miloc[:,columns])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/siddh/OneDrive/Documents/Metaheuristics-In-Healthcare/1.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    457\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    458\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    459\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    460\u001b[0m )(\n\u001b[0;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    462\u001b[0m         t,\n\u001b[0;32m    463\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    464\u001b[0m         X,\n\u001b[0;32m    465\u001b[0m         y,\n\u001b[0;32m    466\u001b[0m         sample_weight,\n\u001b[0;32m    467\u001b[0m         i,\n\u001b[0;32m    468\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    469\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    470\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    471\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    472\u001b[0m     )\n\u001b[0;32m    473\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    474\u001b[0m )\n\u001b[0;32m    476\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    930\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \n\u001b[0;32m    932\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_fit(\n\u001b[0;32m    960\u001b[0m         X,\n\u001b[0;32m    961\u001b[0m         y,\n\u001b[0;32m    962\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    963\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    964\u001b[0m     )\n\u001b[0;32m    965\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    445\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_generations = 20\n",
    "for generation in range(num_generations):\n",
    "    # Measing the fitness of each chromosome in the population.\n",
    "    fitness = cal_pop_fitness(new_population, X_train,y_train,X_test,y_test)\n",
    "\n",
    "    print(fitness)\n",
    "\n",
    "    # Selecting the best parents in the population for mating.\n",
    "    parents = select_mating_pool(new_population, fitness, \n",
    "                                      num_parents_mating)\n",
    "    \n",
    "    # print(parents)\n",
    "\n",
    "    # Generating next generation using crossover.\n",
    "    offspring_crossover = crossover(parents,\n",
    "                                       offspring_size=(pop_size[0]-parents.shape[0], col_len))\n",
    "\n",
    "\n",
    "    # Adding some variations to the offsrping using mutation.\n",
    "    offspring_mutation = mutation(offspring_crossover)\n",
    "\n",
    "    # print(offspring_mutation)\n",
    "\n",
    "    # Creating the new population based on the parents and offspring.\n",
    "    new_population[0:parents.shape[0], :] = parents\n",
    "    new_population[parents.shape[0]:, :] = offspring_mutation  # should be offspring_mutation\n",
    "\n",
    "    # The best result in the current iteration.\n",
    "    if generation%10 ==0:\n",
    "        print(\"Generation : \", generation)\n",
    "        # print(offspring_crossover)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution fitness :  0.933\n"
     ]
    }
   ],
   "source": [
    "# Getting the best solution after iterating finishing all generations.\n",
    "#At first, the fitness is calculated for each solution in the final generation.\n",
    "fitness = cal_pop_fitness(new_population, X_train, y_train, X_test,y_test)\n",
    "# Then return the index of that solution corresponding to the best fitness.\n",
    "best_match_idx = np.where(fitness == np.max(fitness))\n",
    "\n",
    "# print(\"Best solution : \", new_population[best_match_idx, :])\n",
    "print(\"Best solution fitness : \", fitness[best_match_idx[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution :  [[[457 603 536 553  55 432 653 378 304 635 698 275 265 260 539 210 260\n",
      "   519 238 308 187 267 305 368 525 434 454 689 217 492 539 349 185 345\n",
      "   577 129 443 417 665 339 628 265 313 281 375 319 313 565 283 577 516\n",
      "   430 593 334 525 287 354 460 409 470 622 417 425 309 307 600 276 475\n",
      "   216 269 414 210 479 290 474 300 576 374  14 272 336 337 463 256 526\n",
      "   236 359 348 467 342 324 217 350 333 567 277 553 352 421 438 233 231\n",
      "   370 487 521 270 485 551 355 409 460 221]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Best solution : \", new_population[best_match_idx, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9667619047619047\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = new_population[best_match_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([457, 603, 536, 553,  55, 432, 653, 378, 304, 635, 698, 275, 265,\n",
       "       260, 539, 210, 260, 519, 238, 308, 187, 267, 305, 368, 525, 434,\n",
       "       454, 689, 217, 492, 539, 349, 185, 345, 577, 129, 443, 417, 665,\n",
       "       339, 628, 265, 313, 281, 375, 319, 313, 565, 283, 577, 516, 430,\n",
       "       593, 334, 525, 287, 354, 460, 409, 470, 622, 417, 425, 309, 307,\n",
       "       600, 276, 475, 216, 269, 414, 210, 479, 290, 474, 300, 576, 374,\n",
       "        14, 272, 336, 337, 463, 256, 526, 236, 359, 348, 467, 342, 324,\n",
       "       217, 350, 333, 567, 277, 553, 352, 421, 438, 233, 231, 370, 487,\n",
       "       521, 270, 485, 551, 355, 409, 460, 221])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9505714285714286\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_classifier.fit(X_train.iloc[:,feat[0][0]], y_train)\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test.iloc[:,feat[0][0]])\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
